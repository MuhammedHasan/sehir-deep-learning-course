{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I write code to scrap poems for biggerst turkish poem website which is antoloji.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class Antoloji(scrapy.Spider):\n",
    "    name = 'Antoloji'\n",
    "    url = 'https://www.antoloji.com'\n",
    "    poet = 'oktay-rifat'\n",
    "\n",
    "    def start_requests(self):\n",
    "        yield scrapy.Request('%s/%s/siirleri/' % (self.url, self.poet),\n",
    "                             self.parse_all)\n",
    "\n",
    "    def parse_all(self, response):\n",
    "        for i in range(1, len(response.css('.pagination li')) - 1):\n",
    "            yield scrapy.Request('%s/%s/siirleri/ara-/sirala-/sayfa-%s/' %\n",
    "                                 (self.url, self.poet, i), self.parse_list)\n",
    "\n",
    "    def parse_list(self, response):\n",
    "        for i in response.css('.poemListBox a::attr(href)').extract():\n",
    "            yield scrapy.Request(self.url + i, self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        with open('poets/%s.txt' % self.poet, 'a') as f:\n",
    "            text = ''.join(response.css('.pd-text p::text').extract())\n",
    "            f.write(text)\n",
    "            yield {'poem': text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Dropout, SimpleRNN, GRU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implement textgenerator with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TextGenerator:\n",
    "    def __init__(self, seq_len=50, temperature=0.8, epoch=50, rnn_layer=LSTM):\n",
    "        self.seq_len = seq_len\n",
    "        self.temperature = temperature\n",
    "        self.epochs = epoch\n",
    "        self.rnn_layer = rnn_layer\n",
    "\n",
    "    def read_data(self, files_paths):\n",
    "        self.text = '\\n'.join(open(path).read()\n",
    "                              for path in files_paths).lower()\n",
    "        self.set_vocab_mapping(self.text)\n",
    "        return self.text_vec(self.text)\n",
    "\n",
    "    def text_vec(self, text):\n",
    "        sentences = []\n",
    "        next_chars = []\n",
    "        for i in range(0, len(text) - self.seq_len):\n",
    "            sentences.append(text[i:i + self.seq_len])\n",
    "            next_chars.append(text[i + self.seq_len])\n",
    "        \n",
    "        X = np.zeros(\n",
    "            (len(sentences), self.seq_len, self.vocab_len), dtype=np.bool)\n",
    "        y = np.zeros((len(sentences), self.vocab_len), dtype=np.bool)\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            for t, char in enumerate(sentence):\n",
    "                X[i, t, self.char_indices[char]] = 1\n",
    "            y[i, self.char_indices[next_chars[i]]] = 1\n",
    "        return X, y\n",
    "\n",
    "    def set_vocab_mapping(self, text):\n",
    "        chars = sorted(list(set(text)))\n",
    "        self.vocab_len = len(chars)\n",
    "        self.char_indices = {c: i for i, c in enumerate(chars)}\n",
    "        self.indices_char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "    def build_nn(self):\n",
    "        print(self.seq_len, self.vocab_len)\n",
    "        model = Sequential()\n",
    "        model.add(self.rnn_layer(256, input_shape=(self.seq_len, self.vocab_len)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(self.vocab_len))\n",
    "        model.add(Activation('softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.build_nn()\n",
    "        filepath = \"models/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            filepath,\n",
    "            monitor='loss',\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            mode='min')\n",
    "        self.model.fit(\n",
    "            X, y, epochs=self.epochs, batch_size=128, callbacks=[checkpoint])\n",
    "\n",
    "    def diversity(self, preds):\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.log(preds) / self.temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "        return np.argmax(probas)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X, verbose=0)[0]\n",
    "\n",
    "    def generate(self):                                                                                                                                                                                             \n",
    "        sentence = self.get_random_sentence()                                                                                                                                                                       \n",
    "        generated = list()                                                                                                                                                                                          \n",
    "        for i in range(400):                                                                                                                                                                                        \n",
    "            X, _ = self.text_vec(sentence)                                                                                                                                                                          \n",
    "            next_index = self.diversity(self.predict(X))                                                                                                                                                            \n",
    "            next_char = self.indices_char[next_index]                                                                                                                                                               \n",
    "            sentence = sentence[1:] + next_char                                                                                                                                                                     \n",
    "            generated.append(next_char)                                                                                                                                                                             \n",
    "        return ''.join(generated)                                                                                                                                                                                   \n",
    "     \n",
    "    def get_random_sentence(self):\n",
    "        start_index = random.randint(0, len(self.text) - self.seq_len - 1)\n",
    "        return self.text[start_index:start_index + self.seq_len + 1]\n",
    "\n",
    "    def load(self, path):\n",
    "        self.model.load_weights(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleRnn results do not make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğuu  koipşleerdii\n",
      "\n",
      "b ut uk uçdıuğ ubçaağ ıölmüeşreezlierr ebtii  öoltuosyuas aallıağnıuz ashkell igbiil e dbeenciel ekkeis ebseinm eşrtim\n",
      "aaüy ok\n",
      "urmaas ıullkaıt ıglea  k ibkiinç ek lgaüztcee\n",
      " p,e lgeel een eks isçteun ekntiarcaı \n",
      "yseenlier  iȧ kvaurllaartıu,  kbeer ebnia  vç  kbael abdeık  beanz ı\n",
      "çveep eyneen lbeirnt iiemt etn ikçdiu\n",
      "myean  k agğiı  gaien  as tiabniaylaa rıollaarn  ös üünrüey e\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "text_generator = TextGenerator(rnn_layer=SimpleRNN, epoch=20)\n",
    "X, y = text_generator.read_data(['poets/sezai-karakoc.txt'])\n",
    "text_generator.fit(X, y)\n",
    "\n",
    "clear_output()\n",
    "print(text_generator.generate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU is not looks well too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "şyüü kköarleırl\n",
      "ıgşıaml aknlaam ıbşaadtımr aelsein\n",
      "bbiurtmuaşctamlaarlıağlıa ykaen ekdtii\n",
      "çbeirtiirlie  adkeıllaıd akc agkıınmdaannıeş ıprdaanl agtıamn eslkii  açkıır\n",
      "agyaalt ukğuunmuaşlkae skaartlıa mdiemkeer einkdeilmaezlierleedleer\n",
      "edneim  öblüey oblua msaantaırlaarckıımr\n",
      "aasyıalnaızm aşckıssıaz\n",
      "\n",
      "aacmaanl adcaakl akr agliayr ıgkaaylıa ykaanm adyaaltaın çkoılrma  m\n",
      "esrkiiş\n",
      "teenm eşştiil mdeun\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "text_generator = TextGenerator(rnn_layer=GRU, epoch=20)\n",
    "X, y = text_generator.read_data(['poets/sezai-karakoc.txt'])\n",
    "text_generator.fit(X, y)\n",
    "\n",
    "clear_output()\n",
    "print(text_generator.generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğuu  koipşleerdii\n",
      "\n",
      "b ut uk uçdıuğ ubçaağ ıölmüeşreezlierr ebtii  öoltuosyuas aallıağnıuz ashkell igbiil e dbeenciel ekkeis ebseinm eşrtim\n",
      "aaüy ok\n",
      "urmaas ıullkaıt ıglea  k ibkiinç ek lgaüztcee\n",
      " p,e lgeel een eks isçteun ekntiarcaı \n",
      "yseenlier  iȧ kvaurllaartıu,  kbeer ebnia  vç  kbael abdeık  beanz ı\n",
      "çveep eyneen lbeirnt iiemt etn ikçdiu\n",
      "myean  k agğiı  gaien  as tiabniaylaa rıollaarn  ös üünrüey e\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "text_generator = TextGenerator(rnn_layer=LSTM, epoch=20)\n",
    "X, y = text_generator.read_data(['poets/sezai-karakoc.txt'])\n",
    "text_generator.fit(X, y)\n",
    "\n",
    "clear_output()\n",
    "print(text_generator.generate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result are too bad. Probably there is bug in my implementation because I obtain better result with using other implentation from internet but I could not find the bug alhough I debug it for a day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
