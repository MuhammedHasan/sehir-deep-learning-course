{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import struct\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.special import expit\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurol Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetMLP(object):\n",
    "\n",
    "    def __init__(self, n_output, n_features, n_hidden=30, c=0.001, epochs=500, eta=0.001, batch_size=50):\n",
    "        np.random.seed(43)\n",
    "        tf.set_random_seed(43)\n",
    "        self.n_output = n_output\n",
    "        self.n_features = n_features\n",
    "        self.n_hidden = n_hidden\n",
    "        self.w1, self.w2, self.b1, self.b2 = self._initialize_weights()\n",
    "        self.c = c\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.batch_size = batch_size\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "    def _encode_labels(self, y):\n",
    "        onehot = np.zeros((self.n_output, y.shape[0]))\n",
    "        for idx, val in enumerate(y):\n",
    "            onehot[val, idx] = 1.0\n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        return [\n",
    "            tf.Variable(tf.random_normal(shape)) \n",
    "            for shape in [\n",
    "                (self.n_features, self.n_hidden), \n",
    "                (self.n_hidden, self.n_output), \n",
    "                (self.n_hidden,), \n",
    "                (self.n_output,)\n",
    "            ]]\n",
    "\n",
    "    def _feedforward(self, x):\n",
    "        hidden_layer = tf.nn.sigmoid(tf.add(tf.matmul(x, self.w1), self.b1))\n",
    "        return tf.nn.sigmoid(tf.add(tf.matmul(hidden_layer, self.w2), self.b2))\n",
    "    \n",
    "    def _regularization(self):\n",
    "        return (tf.nn.l2_loss(self.w1) + tf.nn.l2_loss(self.w2))\n",
    "\n",
    "    def _loss(self, prediction, y):\n",
    "        return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "    \n",
    "    def _cost(self, prediction, y):\n",
    "        return tf.reduce_mean(self._loss(prediction, y) + self.c * self._regularization())\n",
    "    \n",
    "    def fit(self, X, labels, print_progress=False):\n",
    "        self._x = tf.placeholder(\"float\", [None, self.n_features])\n",
    "        y = tf.placeholder(\"float\", [None, self.n_output])\n",
    "\n",
    "        prediction = self._feedforward(self._x)\n",
    "        self._predict = tf.argmax(prediction, axis=1)\n",
    "        cost = self._cost(prediction, y)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.eta).minimize(cost)\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        total_batch = int(X.shape[0] / self.batch_size)\n",
    "        encode_y = self._encode_labels(labels).T\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(total_batch):\n",
    "                X_batch = X[self.batch_size * i : self.batch_size* (i + 1)]\n",
    "                y_batch = encode_y[self.batch_size * i : self.batch_size* (i + 1)]\n",
    "                _, c = self.sess.run([optimizer, cost], feed_dict={self._x: X_batch , y: y_batch })\n",
    "            if epoch % 1000 == 0:\n",
    "                print(\"Epoch:\", epoch + 1, \"cost=\", c)\n",
    "        print(\"End\")\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.sess.run(self._predict, feed_dict={self._x: X})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FaceDirectionPredictor(object):\n",
    "\n",
    "    def __init__(self, labels=('left', 'straight', 'right',  'up')):\n",
    "        self.file_label_number = 1\n",
    "        self.labels = labels\n",
    "        self.directions = {j: i for i, j in enumerate(self.labels)}\n",
    "        self._model = object()\n",
    "        self.l2 = 0.1\n",
    "        self.l1 = 0.0\n",
    "        self.epochs = 10000\n",
    "        self.eta = 0.001\n",
    "        self.alpha = 0.001\n",
    "        self.decrease_const = 0.00001\n",
    "        self.minibatches = 50\n",
    "\n",
    "    def _labels_to_number(self, label):\n",
    "        return self.directions[label]\n",
    "\n",
    "    def _number_to_label(self, number):\n",
    "        return self.labels[number]\n",
    "\n",
    "    @staticmethod\n",
    "    def compress_image(pic):\n",
    "        \"\"\"\n",
    "        Compress image to half size\n",
    "        pic: np array of dimensions M x N\n",
    "        return: np array of dimensions M/2 x N/2\n",
    "        \"\"\"\n",
    "        return np.array([\n",
    "            pic[m:m + 2, n:n + 2].sum() / 4.0\n",
    "            for m in range(0, pic.shape[0], 2)\n",
    "            for n in range(0, pic.shape[1], 2)\n",
    "        ]).reshape((int(pic.shape[0] / 2), int(pic.shape[1] / 2)))\n",
    "\n",
    "    def _pic_to_features(self, pic):\n",
    "        '''\n",
    "        Convert pictures to two time compressed feature array\n",
    "        pic: np array of dimensions M x N\n",
    "        return: np array of one dimensions with size M/4 * N/4\n",
    "        '''\n",
    "        return self.compress_image(self.compress_image(pic)).reshape(-1)\n",
    "\n",
    "    def _read_pics(self, folder=\"TrainingSet\"):\n",
    "        '''\n",
    "        Reads all image and labels from given folder\n",
    "        folder: TrainingSet or TestSet\n",
    "        return: list of tuple of label and image matrix\n",
    "        '''\n",
    "        return [(np.asarray(Image.open(folder + \"/\" + i).convert('L')),\n",
    "                 i.split('_')[self.file_label_number])\n",
    "                for i in os.listdir(folder)]\n",
    "\n",
    "    def _pic_to_X_y(self, folder=\"TrainingSet\"):\n",
    "        '''\n",
    "        Convert traing set pictures to X and y\n",
    "        return: tuple of X, y\n",
    "        '''\n",
    "        return map(np.asarray, zip(*[\n",
    "            (\n",
    "                self._pic_to_features(pic),\n",
    "                self._labels_to_number(label)\n",
    "            )\n",
    "            for pic, label in self._read_pics()\n",
    "        ]))\n",
    "\n",
    "    def fit(self):\n",
    "        '''\n",
    "        Fits data for traing set\n",
    "        '''\n",
    "        self._model = NeuralNetMLP(c=self.l2, epochs=self.epochs, eta=self.eta, n_output=4, n_features=960)\n",
    "        (X, y) = self._pic_to_X_y()\n",
    "        self._model.fit(X, y)\n",
    "\n",
    "    def predict(self, pic):\n",
    "        '''\n",
    "        pic: np array of dimensions 120 x 128 representing an image\n",
    "        return: String specifying direction that the subject is facing\n",
    "        '''\n",
    "        x = self._pic_to_features(pic)\n",
    "        return self._number_to_label(self._model.predict(np.array([x]))[0])\n",
    "\n",
    "    def __str__(self):\n",
    "        return ' '.join([\n",
    "            str(self.labels),\n",
    "            \"l2:\", str(self.l2),\n",
    "            \"l1:\", str(self.l1),\n",
    "            \"epochs:\", str(self.epochs),\n",
    "            \"eta:\", str(self.eta),\n",
    "            \"alpha:\", str(self.alpha),\n",
    "            \"decrease_const:\", str(self.decrease_const),\n",
    "            \"minibatches:\", str(self.minibatches)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmotionFeltPredictor(FaceDirectionPredictor):\n",
    "\n",
    "    def __init__(self, labels=('neutral', 'sad', 'angry', 'happy')):\n",
    "        super(self.__class__, self).__init__(labels)\n",
    "        self.file_label_number = 2\n",
    "        self.l2 = 0.01\n",
    "\n",
    "    @staticmethod\n",
    "    def compress_border(pic):\n",
    "        x, y = pic.shape\n",
    "        return pic[int(x / 4):int(x * 3 / 4), int(y / 4):int(y * 3 / 4)]\n",
    "\n",
    "    def _pic_to_features(self, pic):\n",
    "        '''\n",
    "        Convert pictures to two time compressed feature array\n",
    "        pic: np array of dimensions M x N\n",
    "        return: np array of one dimensions with size M/4 * N/4\n",
    "        '''\n",
    "        return self.compress_image(self.compress_border(pic)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def accuracy(model):\n",
    "    print(str(model))\n",
    "\n",
    "    (matrixs, labels) = zip(*model._read_pics())\n",
    "    predicted_labels = [model.predict(m) for m in matrixs]\n",
    "    score = accuracy_score(labels, predicted_labels)\n",
    "    print('train accuracy: %s ' % score)\n",
    "\n",
    "    (matrixs, labels) = zip(*model._read_pics('TestSet'))\n",
    "    predicted_labels = [model.predict(m) for m in matrixs]\n",
    "    score = accuracy_score(labels, predicted_labels)\n",
    "    print('test accuracy: %s ' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B without hyperparamater optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost= 1431.46\n",
      "Epoch: 1001 cost= 1.24864\n",
      "Epoch: 2001 cost= 1.24372\n",
      "Epoch: 3001 cost= 1.21121\n",
      "Epoch: 4001 cost= 1.23506\n",
      "Epoch: 5001 cost= 1.2235\n",
      "Epoch: 6001 cost= 1.25993\n",
      "Epoch: 7001 cost= 1.21988\n",
      "Epoch: 8001 cost= 1.2613\n",
      "Epoch: 9001 cost= 1.23\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "direction_predictor = FaceDirectionPredictor()\n",
    "direction_predictor.l1 = 0\n",
    "direction_predictor.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('left', 'straight', 'right', 'up') l2: 0.1 l1: 0 epochs: 10000 eta: 0.001 alpha: 0.001 decrease_const: 1e-05 minibatches: 50\n",
      "train accuracy: 0.977777777778 \n",
      "test accuracy: 0.977777777778 \n"
     ]
    }
   ],
   "source": [
    "accuracy(direction_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part c with hyperparamater optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost= 1454.55\n",
      "Epoch: 1001 cost= 1.24857\n",
      "Epoch: 2001 cost= 1.23577\n",
      "Epoch: 3001 cost= 1.24777\n",
      "Epoch: 4001 cost= 1.2128\n",
      "Epoch: 5001 cost= 1.21919\n",
      "Epoch: 6001 cost= 1.23164\n",
      "Epoch: 7001 cost= 1.23283\n",
      "Epoch: 8001 cost= 1.24194\n",
      "Epoch: 9001 cost= 1.2393\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "direction_predictor = FaceDirectionPredictor()\n",
    "direction_predictor.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('left', 'straight', 'right', 'up') l2: 0.1 l1: 0.0 epochs: 10000 eta: 0.001 alpha: 0.001 decrease_const: 1e-05 minibatches: 50\n",
      "train accuracy: 0.987301587302 \n",
      "test accuracy: 0.988888888889 \n"
     ]
    }
   ],
   "source": [
    "accuracy(direction_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part d face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost= 145.733\n",
      "Epoch: 1001 cost= 31.8213\n",
      "Epoch: 2001 cost= 7.34582\n",
      "Epoch: 3001 cost= 2.29287\n",
      "Epoch: 4001 cost= 1.49015\n",
      "Epoch: 5001 cost= 1.40712\n",
      "Epoch: 6001 cost= 1.33795\n",
      "Epoch: 7001 cost= 1.33143\n",
      "Epoch: 8001 cost= 1.31391\n",
      "Epoch: 9001 cost= 1.32125\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "emotion_predictor = EmotionFeltPredictor()\n",
    "emotion_predictor.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('neutral', 'sad', 'angry', 'happy') l2: 0.01 l1: 0.0 epochs: 10000 eta: 0.001 alpha: 0.001 decrease_const: 1e-05 minibatches: 50\n",
      "train accuracy: 0.288888888889 \n",
      "test accuracy: 0.266666666667 \n"
     ]
    }
   ],
   "source": [
    "accuracy(emotion_predictor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
